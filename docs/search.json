[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistics Notes",
    "section": "",
    "text": "Preface\nThis is a Quarto book.\nIt contains my notes on various things related to applied statistics."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "Some general remarks about statistics and sociology"
  },
  {
    "objectID": "00-regression.html",
    "href": "00-regression.html",
    "title": "Regression",
    "section": "",
    "text": "add stuff here."
  },
  {
    "objectID": "std-errors.html#standard-errors",
    "href": "std-errors.html#standard-errors",
    "title": "2  Standard Errors",
    "section": "2.1 Standard Errors",
    "text": "2.1 Standard Errors\nWe calculate the standard error because we want to know the standard deviation of that sampling distribution. But our standard errors are probably always wrong.\nTwo assumptions:\n\n\\(\\varepsilon\\) is normally distributed.\n\\(\\varepsilon\\) is independent and identically distributed.\n\nThese assumptions are most obviously false when dealing with time series or data that’s geographically clustered (i.e., temporal or spatial autocorrelation).\nThere could also be heteroskedasticity—i.e., the variance of \\(\\varepsilon\\) is related to other variables in the model.\nFixing Standard Errors\n\nHeteroskedasticity-robust sandwich estimator (e.g., Huber-White). We weight observations with big residuals more when calculating the variance.\n\\[\n(\\boldsymbol{X^\\top X})^{-1}(\\boldsymbol{X^\\top \\Sigma X}) (\\boldsymbol{X}^\\top X)^{-1}\n\\]\nHeteroskedasticity and Autocorrelation Consistent (HEC) standard errors (e.g., Newey-West).\nClustered standard errors. Why not go with multilevel models instead?\nBootstrap methods.\n\n\nSandwich estimators leave the coefficient estimates (\\(\\boldsymbol{\\hat \\beta}\\)) intact!\n\nWhy do economists care so much about standard errors? They have a toxic culture that values “gotcha!” moments during conference presentations.\nWe can use the estimatr package to easily calculate these robust standard errors.\n\nlibrary(estimatr)\ndata(restaurant_inspections, package = \"causaldata\")\n\nm1 <- lm(inspection_score ~ Year + Weekend, \n         data = restaurant_inspections)\n\nm2 <- lm_robust(inspection_score ~ Year + Weekend, \n          data = restaurant_inspections, \n          se_type = \"HC1\"\n)\n\nmodelsummary::msummary(list(m1, m2), gof_omit = \".\")\n\n\n\n \n  \n      \n     (1) \n      (2) \n  \n \n\n  \n    (Intercept) \n    185.380 \n    185.380 \n  \n  \n     \n    (12.809) \n    (12.149) \n  \n  \n    Year \n    −0.046 \n    −0.046 \n  \n  \n     \n    (0.006) \n    (0.006) \n  \n  \n    WeekendTRUE \n    2.057 \n    2.057 \n  \n  \n     \n    (0.433) \n    (0.351) \n  \n\n\n\n\n\nThis is how the matrix algebra works:\n\nX <- model.matrix(m1)\nA <- solve(t(X) %*% X) \nr <- m1$residuals\nB <- (t(X) %*% diag(r^2) %*% X)\nvarB <- A %*% B %*% A\nsqrt(diag(varB)) ## robust standard errors\n\n(Intercept)        Year WeekendTRUE \n12.14823297  0.00604299  0.35122580 \n\n\nSee King and Roberts (2015) for more.\n\n\n\n\nKing, Gary, and Margaret E. Roberts. 2015. “How Robust Standard Errors Expose Methodological Problems They Do Not Fix, and What to Do About It.” Political Analysis 23 (2): 159–79. https://doi.org/10.1093/pan/mpu015."
  },
  {
    "objectID": "marginal-effects.html",
    "href": "marginal-effects.html",
    "title": "3  Marginal Effects",
    "section": "",
    "text": "https://theeffectbook.net/ch-StatisticalAdjustment.html#eq:regression-15\nMarginal effect at the mean. Icky.\nAverage Marginal effects."
  },
  {
    "objectID": "00-causality.html#notation",
    "href": "00-causality.html#notation",
    "title": "Causality",
    "section": "Notation",
    "text": "Notation\nThe difference between seeing and doing is monumental. It explains why we do not regard movements in a thermostat to be a cause of the temperature outside.\n\\[\n\\Pr(Y \\mid T) \\neq \\Pr(Y \\mid do(T))\n\\]\n\nPearl\n\nPotential Outcomes\n\n\\(T\\) is a binary treatment variable. The terms “treatment” and “cause” are used interchangeably.\n\\(Y\\) is the outcome we observe.\n\\(Y^0\\) is the the value the outcome would take if \\(T=0\\).\n\\(Y^1\\) is the value the outcome would take if \\(T=1\\).\n\\(Y^0\\) and \\(Y^1\\) are the potential outcomes.\nWe see \\(Y^0\\) or \\(Y^1\\) for the same unit, but never both. This is the fundamental problem of causal inference.\nWhen \\(T=1\\), \\(Y^0\\) is the counterfactual.\nWhen \\(T=0\\), \\(Y^1\\) is the counterfactual.\n\n\nRubin\n\nOne might object to the fundamental problem of causal inference by noting situations where we can actually measure both \\(Y^0\\) and \\(Y^1\\) on the same unit \\(i\\). For example, we could drink warm milk one evening and coffee another evening, and then measure our amount of sleep time. Holland (1986) refers to this as temporal stability and causal transience. This is the same situation in which we flick the same light switch on and off to figure out if it turns on the light to a room. In other settings, it is perfectly reasonable to assume that \\(Y^1_i = Y^1_j\\) and that \\(Y^0_i = Y^0_j\\) (unit homogeneity assumption). For example, this is very common in laboratories that take special care in standardizing the units of an experiment (e.g., mice).\n\nThese objections are unrealistic in the social sciences."
  },
  {
    "objectID": "00-causality.html#experiments",
    "href": "00-causality.html#experiments",
    "title": "Causality",
    "section": "Experiments",
    "text": "Experiments\nExperiments work because they make the distribution of potential outcomes the same across levels of the treatment variable. In other words, the potential outcomes and the treatment indicator are independent.\n\\[\nY^0, Y^1 \\perp T\n\\]\nThus, in expectation:\n\\[\nE[Y^0 \\mid T = 0] = E[Y^0 \\mid T = 1] \\\\\nE[Y^1 \\mid T = 0] = E[Y^1 \\mid T = 1]\n\\tag{1}\\]\nWhich means that we can easily estimate the average causal effect of \\(T\\) over all units in a population:\n\\[\n\\text{ATE} = \\underbrace{E[Y^1 - Y^0] = E[Y^1] - E[Y^0]}_\\text{linearity of expectations}\n\\tag{2}\\]\nIn the absence of randomization, so that treatment and control groups differ on pre-treatment characteristics, we might observe the following biases:\n\nBaseline bias. The two groups might be different from each other whether they get treated or not.\nTreatment effect heterogeneity. The two groups might respond differently to the treatment.\nThis is important because researchers sometimes assume a constant effect for every unit in the population. This is implied in the unit homogeneity assumption. But if the variability of causal effects is large across the population, then the ATE might not represent the causal effect of a specific unit very well; the ATE might be irrelevant, no matter how carefully we estimate it.\n\nThree types of treatment effects:\n\n\\(\\text{ATE}\\), for all units (effect of switching)\n\\(\\text{ATT}\\), for treated units (effect of taking away treatment)\n\\(\\text{ATC}\\) or \\(\\text{ATU}\\), for untreated units (effect of adding treatment)\n\n\nSome times we see these terms pre-fixed with an \\(S\\) (for sample) or a \\(P\\) (for population).\n\nExample:\n\n\n\nGroup (\\(T\\))\n\\(E[Y^1]\\)\n\\(E[Y^0]\\)\n\n\n\n\nCollege Degree (\\(T = 1\\))\n1000\n600*\n\n\nNo Degree (\\(T = 0\\))\n800*\n500\n\n\n\n\n* means unobservable\n\nIf 30% of the population has a degree…\n\nWhat is the naive estimate?\n500\nWhat is the ATT?\n400\nWhat is the ATC?\n300\nWhat is the ATE?\n\\(0.3\\times 400 + 0.7 \\times 300 = 330\\)\n\nMore than two treatment levels, continuous treatments, and multiple treatment factors\nGELMAN"
  },
  {
    "objectID": "00-causality.html#identification-and-causal-diagrams",
    "href": "00-causality.html#identification-and-causal-diagrams",
    "title": "Causality",
    "section": "Identification and Causal Diagrams",
    "text": "Identification and Causal Diagrams\nIdentification refers to the idea of identifying the effect of a treatment (or cause) on an outcome.\n\nIdentification is the process of figuring out what part of the variation in your data answers your research question. It’s called identification because we’ve ensured that our calculation identifies a single theoretical mechanism of interest. In other words, we’ve gotten past all the misleading clues and identified our culprit.\nHuntington-Klein (2021, 77)\n\nCausal diagrams or DAGs are graphical representations of a data generating process. Everything we draw is hopefully an informed assumption; everything that’s not in the diagram is also an assumption. In other words, DAGs encode identifying assumptions.\n\nPaths.\nDirect effects.\nIndirect effects.\nTotal effects.\nFront door paths. They point away from the treatment. If we want to estimate “total effects,” then we want to keep all of them open.\nBack door paths. They point towards the treatment; we want to close them off.\nConfounding. A property of paths, not of variables.\nColliders. A variable is a collider in a path iff both arrows point at it.\n\\[\na \\to b \\to c_\\text{ollider} \\leftarrow d \\leftarrow e \\to f\n\\]\nHere, \\(b\\) and \\(c\\) are unrelated unless we remove variation in \\(c\\).\nIn other words, we close paths by removing variation from one variable along the path (i.e., adjusting); but if the variable is a collider, then removing variation will actually open a path that was already closed.\nAn often unacknowledged way of adjusting for colliders is during the sample selection phase. If we have a sample of college students, it means we are adjusting for college attendance.\nOpen Path. A path in which there is variation in all variables along the path (and no variation in colliders).\nClosed Path. A path in which there is at least one variable with no variation (or a collider with variation).\n\nThe idea of a directed acyclical graph (DAG) implies that there are no cycles. If a variable causes itself, it’s near impossible to isolate or identifying the cause of anything. The world is full with feedback loops of all sorts, but we deal with them through the incorporation of time or by isolating one effect through some kind of experimental scenario.\nNote that DAGs are agnostic about functional form. This includes interactions among variables! Some people deal with interactions by drawing arrows toward arrows or by representing interactions explicitly as separate nodes.\nThe nicest thing about DAGs is that they help us spell out the testable implications of our assumptions. For example, if our causal diagram implies that a relationship between variables is zero, we can check for that (this is called a placebo test).\n\nplacebo test\n\nCausal diagrams also help us understand the idea the idea identification doesn’t necessarily require us to take care of all back door paths; sometimes we can use randomization. Sometimes this is achieved in experimental settings, but sometimes we can form some form of randomization in real-world settings (i.e., natural experiments). Experiments and instrumental variables are depicted equivalently in DAGs (see Figure 1).\n\nfinding front doors using randomization\n\n\n\n\nFigure 1: Randomization\n\n\n\n\n\n\nBollen, Kenneth A. 1989. Structural Equations with Latent Variables. John Wiley & Sons.\n\n\nHolland, Paul W. 1986. “Statistics and Causal Inference.” Journal of the American Statistical Association 81 (396): 945–60. https://doi.org/10.2307/2289064.\n\n\nHuntington-Klein, Nick. 2021. The Effect: An Introduction to Research Design and Causality. New York: Chapman; Hall/CRC. https://doi.org/10.1201/9781003226055."
  },
  {
    "objectID": "01-causality-regression.html#assumptions",
    "href": "01-causality-regression.html#assumptions",
    "title": "4  Regression",
    "section": "4.1 Assumptions",
    "text": "4.1 Assumptions\nThe exogeneity assumption requires that \\(X\\) is uncorrelated with \\(\\varepsilon\\).\nBy adding a variable to a regression we “adjust for it.” The path \\(X \\leftarrow Z \\rightarrow Y\\) is closed in the following regression:\n\\[\nY = \\beta_0 + \\beta_1 X + \\beta_2 Z + \\varepsilon\n\\]\nEvery variable that predicts \\(Y\\) but isn’t contained in the model is then in the error term.\nThe sampling distribution of regression coefficients follows a normal distribution.\nIn the case of one predictor \\(X\\):\n\\[\n\\begin{align}\nY &\\sim \\text{Normal}(\\beta_0 + \\beta_1 X, \\ \\sigma^2) \\\\\\\\\n\\hat{\\beta_i} &\\sim \\text{Normal}(\\beta_i, \\text{SE} (\\hat \\beta_i)^2)\\\\\\\\\n\\text{SE}(\\hat \\beta_1) &= \\sqrt{\\frac{\\hat \\sigma^2}{\\sum_{i=1}^n (x - \\bar x)^2}} = \\sqrt{\\frac{\\hat \\sigma^2}{\\text{var}(X) \\times n}}\n\\end{align}\n\\]\n\nThe standard deviation of a sampling distribution is often referred to as a standard error.\n\nIn the case of multiple predictors (\\(\\mathbf X\\)) and coefficients (\\(\\boldsymbol \\beta\\)):\n\\[\n\\begin{align}\nY &\\sim \\text{Normal}(\\boldsymbol{X \\beta}, \\sigma^2 \\boldsymbol I) \\\\\n\\boldsymbol{\\hat \\beta} &\\sim \\text{Normal}(\\boldsymbol \\beta, \\boldsymbol \\Sigma) \\\\\n\\boldsymbol \\Sigma &=\\widehat{\\text{var}} \\hat{(\\boldsymbol \\beta)} = \\hat \\sigma^2 (\\boldsymbol{X^\\top X})^{-1}\n\\end{align}\n\\]\nThis is what allows us to do hypothesis testingTM on regression coefficients."
  },
  {
    "objectID": "01-causality-regression.html#translating-dags",
    "href": "01-causality-regression.html#translating-dags",
    "title": "4  Regression",
    "section": "4.2 Translating DAGs",
    "text": "4.2 Translating DAGs\n\n\n\nFigure 4.1: Flow Chart For Constructing Regression Equations\n\n\n\nHuntington-Klein (2021, 199)\n\nSuppose our causal diagram is as follows:\n\n\n\n\n\nFurther suppose that the true data generating process is as follows:\n\\[\ny_i = \\beta_0 + \\beta_1 t_i + \\beta_2 z_i + \\varepsilon_i\n\\]\nIf we omit \\(z\\), then our regression is as follows:\n\\[\ny_i = \\beta_0^* + \\beta_1^* t_i+ \\varepsilon^*_i\n\\]\nFinally, suppose that the association between \\(z\\) and \\(t\\) is defined in terms of a third regression:\n\\[\nz_i = \\gamma_0 + \\gamma_1 t_i + u_i\n\\]\nIf we substitute this representation of \\(t\\) into the original “true” regression and rearrange the terms, we the the following:\n\\[\ny_i = \\underbrace{(\\beta_0 + \\beta_2 \\gamma_0)}_{\\beta_0^*} + \\underbrace{(\\beta_1 + \\beta_2 \\gamma_1)}_{\\beta_1^*} + \\underbrace{(\\beta_2 u + \\varepsilon)}_{\\varepsilon^*}\n\\]\nIf there’s no association between the treatment and the purported confounder (\\(\\gamma_1 = 0\\)), then there is no bias.\nIn R:\n\nN <- 1e3\nb0 <- 1 \nb1 <- 2  ## effect of t\nb2 <- 3\ng0 <- 2\ng1 <- 3\n\nd <- tibble::tibble(\n  z = runif(N, min = -50, max = 50),\n  t = rnorm(N, mean = (z - g0)/g1, sd = 1),\n  y = rnorm(N, mean = b0 + b1*t + b2*z, sd = 1)\n)\n\nmtrue <- lm(y ~ t + z, data = d)\nmconf <- lm(y ~ t, data = d)\n\nmodelsummary::msummary(\n  models = list(mtrue, mconf), \n  gof_omit = \".\"\n)\n\n\n\n \n  \n      \n     (1) \n      (2) \n  \n \n\n  \n    (Intercept) \n    0.995 \n    6.676 \n  \n  \n     \n    (0.036) \n    (0.286) \n  \n  \n    t \n    1.992 \n    10.888 \n  \n  \n     \n    (0.030) \n    (0.029) \n  \n  \n    z \n    3.004 \n     \n  \n  \n     \n    (0.010) \n     \n  \n\n\n\n\n\nHere, we see that \\(\\beta_1 \\approx 2\\) and \\(\\beta_1^* \\approx 10\\)."
  },
  {
    "objectID": "01-causality-regression.html#balance",
    "href": "01-causality-regression.html#balance",
    "title": "4  Regression",
    "section": "4.3 Balance",
    "text": "4.3 Balance\n\n\n\n\nHuntington-Klein, Nick. 2021. The Effect: An Introduction to Research Design and Causality. New York: Chapman; Hall/CRC. https://doi.org/10.1201/9781003226055."
  },
  {
    "objectID": "02-matching.html#exact-matching",
    "href": "02-matching.html#exact-matching",
    "title": "5  Matching",
    "section": "5.1 Exact Matching",
    "text": "5.1 Exact Matching\nThe logic of exact matching is relatively straightforward, we want apples to apples comparisons.\nInstead of a simple independence assumption, we now rely on a conditional independence assumption (CIA).\n\\[\n\\begin{align}\nE\\big[Y^1 \\mid T=1, S \\big] &= E\\big[Y^1 \\mid T=0, S \\big] \\\\\nE\\big[Y^0 \\mid T=1, S \\big] &= E\\big[Y^0 \\mid T=0, S \\big]\n\\end{align}\n\\tag{5.1}\\]\n\nIgnorability\n\nThe assumption in Equation 5.1 means that we can observe counterfactuals, conditional on pre-treatment variables \\(S\\). Unfortunately, we cannot test the conditional independence assumption directly.\nThree overall assumptions:\n\nIgnorability or selection on observables.\nOverlap—any individual case has a non-zero probability of treatment.\nStable Unit Treatment Value Assumption (SUTVA)—i.e., no spillovers.\n\nNote. In cases when we have treatment effect heterogeneity, the ATT, ATU, and ATE estimates will be different, as exemplified in Table 5.1.\n\n\nTable 5.1: Treatment Effect Heterogeneity\n\n\nSES\nN\ndegree\nearnings\n\n\n\n\n1\n150\n0\n2,000\n\n\n1\n50\n1\n4,000\n\n\n2\n100\n0\n6,000\n\n\n2\n100\n1\n8,000\n\n\n3\n50\n0\n10,000\n\n\n3\n150\n1\n14,000\n\n\n\n\nWhat is our estimand (Lundberg, Johnson, and Stewart 2021)?\nThe procedure is relatively straightforward:\n\nTake the differences between treated and untreated groups within each stratum of \\(S\\).\nWeight these differences by the right distribution the estimand we are interested in:\n\nATE: weight the differences by the total sample distribution of \\(S\\).\nATT: weight differences by the distribution of \\(S\\) for treated cases.\n\n\nFor Table 5.1:\n\\[\n\\begin{align}\n\\text{ATT} &= \\frac{2000(50) + 2000(100) + 4000(150)}{50 + 100 + 150} = 3,000 \\\\\\\\\n\\text{ATE} &= \\frac{2000 (200) + 2000(200) + 4000(200)}{200 + 200 + 200} = 2,666.7\n\\end{align}\n\\]\nThe ATT is usually our most common estimand because treatment cases tend to be less common than control cases. In some cases, like the one portrayed in Table 5.2, we might not be able to calculate the ATE.\n\n\nTable 5.2: Treatment Effect Heterogeneity (Modified Example)\n\n\n\n\n\n\n\n\nSES\nN\ndegree\nearnings\n\n\n\n\n1\n150\n0\n2,000\n\n\n1\n0\n1\n?\n\n\n2\n100\n0\n6,000\n\n\n2\n100\n1\n8,000\n\n\n3\n50\n0\n10,000\n\n\n3\n150\n1\n14,000\n\n\n\n\nBut the ATT is just as easy to calculate as before:\n\\[\n\\text{ATT} = \\frac{(?)(0) + 2000(100) + 4000(150)}{0 + 100 + 150} = 3,200\n\\]\nCommon Support\nStrata that have only treatment or control cases (not both) are called off support. Strata with both treatment and control cases are in the region of common support.\n\n\n\n\nLundberg, Ian, Rebecca Johnson, and Brandon M. Stewart. 2021. “What Is Your Estimand? Defining the Target Quantity Connects Statistical Evidence to Theory.” American Sociological Review, June, 00031224211004187. https://doi.org/10.1177/00031224211004187."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Bollen, Kenneth A. 1989. Structural Equations with Latent\nVariables. John Wiley & Sons.\n\n\nHolland, Paul W. 1986. “Statistics and Causal Inference.”\nJournal of the American Statistical Association 81 (396):\n945–60. https://doi.org/10.2307/2289064.\n\n\nHuntington-Klein, Nick. 2021. The Effect: An Introduction to\nResearch Design and Causality. New York: Chapman; Hall/CRC. https://doi.org/10.1201/9781003226055.\n\n\nKing, Gary, and Margaret E. Roberts. 2015. “How Robust Standard\nErrors Expose Methodological Problems They Do Not Fix, and What to Do\nAbout It.” Political Analysis 23 (2): 159–79. https://doi.org/10.1093/pan/mpu015.\n\n\nLundberg, Ian, Rebecca Johnson, and Brandon M. Stewart. 2021.\n“What Is Your Estimand? Defining the Target Quantity Connects\nStatistical Evidence to Theory.” American Sociological\nReview, June, 00031224211004187. https://doi.org/10.1177/00031224211004187."
  }
]