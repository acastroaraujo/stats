{
  "hash": "b50c4bfc8f090ef255256ae7b34e926b",
  "result": {
    "markdown": "## Standard Errors\n\nThe **sampling distribution** of regression coefficients follows a normal distribution.\n\nIn the case of one predictor $X$:\n\n$$\n\\begin{align}\nY &\\sim \\text{Normal}(\\beta_0 + \\beta_1 X, \\ \\sigma^2) \\\\\\\\\n\\hat{\\beta_i} &\\sim \\text{Normal}(\\beta_i, \\text{SE} (\\hat \\beta_i)^2)\\\\\\\\\n\\text{SE}(\\hat \\beta_1) &= \\sqrt{\\frac{\\hat \\sigma^2}{\\sum_{i=1}^n (x - \\bar x)^2}} = \\sqrt{\\frac{\\hat \\sigma^2}{\\text{var}(X) \\times n}}\n\\end{align}\n$$\n\n<aside>The standard deviation of a sampling distribution is often referred to as a **standard error**.</aside>\n\nIn the case of multiple predictors ($\\mathbf X$) and coefficients ($\\boldsymbol \\beta$):\n\n$$\n\\begin{align}\nY &\\sim \\text{Normal}(\\boldsymbol{X \\beta}, \\sigma^2 \\boldsymbol I) \\\\\n\\boldsymbol{\\hat \\beta} &\\sim \\text{Normal}(\\boldsymbol \\beta, \\boldsymbol \\Sigma) \\\\\n\\boldsymbol \\Sigma &=\\widehat{\\text{var}} \\hat{(\\boldsymbol \\beta)} = \\hat \\sigma^2 (\\boldsymbol{X^\\top X})^{-1}\n\\end{align}\n$$\n\nThis is what allows us to do *hypothesis testing^TM^* on regression coefficients.\n\nWe calculate the standard error because we want to know the standard deviation of that sampling distribution. But our standard errors are probably always wrong.\n\nTwo assumptions:\n\n-   $\\varepsilon$ *is normally distributed.*\n\n-   $\\varepsilon$ is *independent and identically distributed*.\n\nThese assumptions are most obviously false when dealing with time series or data that's geographically clustered (i.e., temporal or spatial autocorrelation).\n\nThere could also be heteroskedasticity---i.e., the variance of $\\varepsilon$ is related to other variables in the model.\n\n**Fixing Standard Errors**\n\n-   Heteroskedasticity-robust sandwich estimator (e.g., Huber-White). We weight observations with big residuals more when calculating the variance.\n\n    $$\n    (\\boldsymbol{X^\\top X})^{-1}(\\boldsymbol{X^\\top \\Sigma X}) (\\boldsymbol{X}^\\top X)^{-1}\n    $$\n\n-   Heteroskedasticity and Autocorrelation Consistent (HEC) standard errors (e.g., Newey-West).\n\n-   Clustered standard errors. *Why not go with multilevel models instead?*\n\n-   Bootstrap methods.\n\n<aside>Sandwich estimators leave the coefficient estimates ($\\boldsymbol{\\hat \\beta}$) intact!</aside>\n\n*Why do economists care so much about standard errors?* They have a toxic culture that values \"gotcha!\" moments during conference presentations.\n\nWe can use the `estimatr` package to easily calculate these robust standard errors.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(estimatr)\ndata(restaurant_inspections, package = \"causaldata\")\n\nm1 <- lm(inspection_score ~ Year + Weekend, \n         data = restaurant_inspections)\n\nm2 <- lm_robust(inspection_score ~ Year + Weekend, \n          data = restaurant_inspections, \n          se_type = \"HC1\"\n)\n\nmodelsummary::msummary(list(m1, m2), gof_omit = \".\")\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:center;\">  (1) </th>\n   <th style=\"text-align:center;\">   (2) </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> (Intercept) </td>\n   <td style=\"text-align:center;\"> 185.380 </td>\n   <td style=\"text-align:center;\"> 185.380 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:center;\"> (12.809) </td>\n   <td style=\"text-align:center;\"> (12.149) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Year </td>\n   <td style=\"text-align:center;\"> −0.046 </td>\n   <td style=\"text-align:center;\"> −0.046 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:center;\"> (0.006) </td>\n   <td style=\"text-align:center;\"> (0.006) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> WeekendTRUE </td>\n   <td style=\"text-align:center;\"> 2.057 </td>\n   <td style=\"text-align:center;\"> 2.057 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:center;\"> (0.433) </td>\n   <td style=\"text-align:center;\"> (0.351) </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nThis is how the matrix algebra works:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nX <- model.matrix(m1)\nA <- solve(t(X) %*% X) \nr <- m1$residuals\nB <- (t(X) %*% diag(r^2) %*% X)\nvarB <- A %*% B %*% A\nsqrt(diag(varB)) ## robust standard errors\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(Intercept)        Year WeekendTRUE \n12.14823297  0.00604299  0.35122580 \n```\n:::\n:::\n\n\nSee @king2015 for more.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}