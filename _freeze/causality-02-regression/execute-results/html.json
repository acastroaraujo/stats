{
  "hash": "6ca7c3bac0f322ca79fc1e2847575bbf",
  "result": {
    "markdown": "# Regression Adjustments\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Setup\"}\nlibrary(tidyverse)\n```\n:::\n\n\n*This notebook is about regression in the context of causal inference.*\n\nIn the usual context of regression, predictive inference relates to comparisons *between* units. In the context of causal inference, we attempt to make comparisons of different treatments *as if applied to the same units.*\n\nIn order to make causal interpretations of regression coefficients we rely very strong assumptions. In short, causal effects can be estimated with regression if the model includes all confounding variables *and* if the model is correct.\n\n**Temporal ordering**\n\nAll causal inference rests on an assumption so basic that we rarely bother to articulate: the temporal ordering of variables. All causal effects are measured *after* a treatment has been assigned.\n\n> In a retrospective observational study---that is, a study that uses data that have already been collected---the temporal ordering of the variables may be less clear. The most obvious problematic example is when study data come from a cross-sectional design (that is, when data on all variables were collected at the same time). It is possible in such a design that some of the questions refer to events in the past (previous schooling, jobs, health, relationship patterns) such that careful selection of variables may still be able to reflect the proper time ordering. This type of questioning about past events typically yields less reliable information, however. More desirable is a longitudinal design in which the researcher can select variables from different waves of the study.\n>\n> A final warning is in order. If the participants in a study know that a treatment *will* be administered in the future and they know or suspect what treatment group they will be in, they might alter their behavior *even before* the treatment is formally administered. In that case, the measurements taken prior to the treatment cannot be considered to be independent of the treatment and must be handled with the same precaution as other post-treatment variables.\n>\n> @gelman2020 [pp. 415]\n\n## Translating DAGs\n\n![Flow Chart For Constructing Regression Equations [@huntington-klein2021, pp. 199]](images/reg-chart.png){#fig-reg-chart fig-align=\"center\" width=\"70%\"}\n\nSuppose our causal diagram is as follows:\n\n![](images/dag1.png){fig-align=\"center\" width=\"40%\"}\n\nFurther suppose that the true data generating process is as follows:\n\n$$\ny_i = \\beta_0 + \\beta_1 t_i + \\beta_2 z_i + \\varepsilon_i \n$$\n\nIf we omit $z$, then our regression is as follows:\n\n$$\ny_i = \\beta_0^* + \\beta_1^* t_i+ \\varepsilon^*_i\n$$\n\nFinally, suppose that the association between $z$ and $t$ is defined in terms of a third regression:\n\n$$\nz_i = \\gamma_0 + \\gamma_1 t_i + u_i\n$$\n\nIf we substitute this representation of $t$ into the original \"true\" regression and rearrange the terms, we then have the following:\n\n$$\ny_i = \\underbrace{(\\beta_0 + \\beta_2 \\gamma_0)}_{\\beta_0^*} + \\underbrace{(\\beta_1 + \\beta_2 \\gamma_1)}_{\\beta_1^*} \\ t_i + \\underbrace{(\\beta_2 u + \\varepsilon)}_{\\varepsilon^*}\n$$\n\nThus, if there's no association between the treatment and the purported confounder ($\\gamma_1 = 0$), *then there is no bias.*\n\nIn `R`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nN <- 1e3\nb0 <- 1 \nb1 <- 2  ## effect of t\nb2 <- 3\ng0 <- 2\ng1 <- 1  ## source of correlation between t and z\n\nd <- tibble::tibble(\n  z = runif(N, min = -50, max = 50),\n  t = rnorm(N, mean = (z - g0)/g1, sd = 1),\n  y = rnorm(N, mean = b0 + b1*t + b2*z, sd = 1)\n)\n\nmtrue <- lm(y ~ t + z, data = d)\nmconf <- lm(y ~ t, data = d)\n\nmodelsummary::msummary(\n  models = list(\"True DGP\" = mtrue, \"Omitted Variable\" = mconf), \n  gof_map = NA\n)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:center;\"> True DGP </th>\n   <th style=\"text-align:center;\">  Omitted Variable </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> (Intercept) </td>\n   <td style=\"text-align:center;\"> 1.021 </td>\n   <td style=\"text-align:center;\"> 6.963 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:center;\"> (0.074) </td>\n   <td style=\"text-align:center;\"> (0.098) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> t </td>\n   <td style=\"text-align:center;\"> 2.010 </td>\n   <td style=\"text-align:center;\"> 4.994 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:center;\"> (0.033) </td>\n   <td style=\"text-align:center;\"> (0.003) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> z </td>\n   <td style=\"text-align:center;\"> 2.989 </td>\n   <td style=\"text-align:center;\">  </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:center;\"> (0.033) </td>\n   <td style=\"text-align:center;\">  </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nHere, we see that $\\beta_1 \\approx 2$ and $\\beta_1^* \\approx 5$.\n\n### The Electric Company\n\n**Setting up a regression for causal inference**\n\nGoing back to the Electric Company example, we can think of `supp`, whether teachers *chose* to replace or supplementing the regular reading program with the television show, as a different treatment.\n\nGiven that this decision is not randomized, we cannot simply compare outcomes across the two new treatment groups. However, we can *assume* ignorability if we are willing to believe that `pre_test` is the only confounding variable---i.e., that the probability of assignment was determined by the average pre-test scores in that classroom.\n\n*This is a strong assumption, it requires a leap of faith.*\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Setup\"}\nlibrary(tidyverse)\n\ntheme_set(\n  theme_light(base_family = \"Avenir Next Condensed\") +\n  theme(strip.background = element_rect(fill = \"#666666\"))\n)\n\nurl <- \"https://raw.githubusercontent.com/avehtari/ROS-Examples/master/ElectricCompany/data/electric.csv\"\n\nd <- read_csv(url)[-1] |> \n  mutate(across(grade:pair_id, as.integer)) |> \n  filter(treatment == 1)\n```\n:::\n\n\nJust look at the change in coefficient and standard error estimates:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod1 <- lm(post_test ~ supp, data = d)\nmod2 <- lm(post_test ~ supp + pre_test, data = d)\nmod3 <- lm(post_test ~ supp + pre_test + grade, \n           data = mutate(d, grade = factor(grade)))\n\nmodelsummary::msummary(\n  models = list(mod1, mod2, mod3), \n  gof_map = NA\n)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:center;\">  (1) </th>\n   <th style=\"text-align:center;\">   (2) </th>\n   <th style=\"text-align:center;\">   (3) </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> (Intercept) </td>\n   <td style=\"text-align:center;\"> 98.189 </td>\n   <td style=\"text-align:center;\"> 66.758 </td>\n   <td style=\"text-align:center;\"> 61.964 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:center;\"> (2.830) </td>\n   <td style=\"text-align:center;\"> (2.377) </td>\n   <td style=\"text-align:center;\"> (2.467) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> supp </td>\n   <td style=\"text-align:center;\"> 2.816 </td>\n   <td style=\"text-align:center;\"> 3.468 </td>\n   <td style=\"text-align:center;\"> 3.589 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:center;\"> (3.550) </td>\n   <td style=\"text-align:center;\"> (1.796) </td>\n   <td style=\"text-align:center;\"> (1.658) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> pre_test </td>\n   <td style=\"text-align:center;\">  </td>\n   <td style=\"text-align:center;\"> 0.424 </td>\n   <td style=\"text-align:center;\"> 0.820 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:center;\">  </td>\n   <td style=\"text-align:center;\"> (0.026) </td>\n   <td style=\"text-align:center;\"> (0.093) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> grade2 </td>\n   <td style=\"text-align:center;\">  </td>\n   <td style=\"text-align:center;\">  </td>\n   <td style=\"text-align:center;\"> −24.741 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:center;\">  </td>\n   <td style=\"text-align:center;\">  </td>\n   <td style=\"text-align:center;\"> (5.992) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> grade3 </td>\n   <td style=\"text-align:center;\">  </td>\n   <td style=\"text-align:center;\">  </td>\n   <td style=\"text-align:center;\"> −34.816 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:center;\">  </td>\n   <td style=\"text-align:center;\">  </td>\n   <td style=\"text-align:center;\"> (7.613) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> grade4 </td>\n   <td style=\"text-align:center;\">  </td>\n   <td style=\"text-align:center;\">  </td>\n   <td style=\"text-align:center;\"> −37.935 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:center;\">  </td>\n   <td style=\"text-align:center;\">  </td>\n   <td style=\"text-align:center;\"> (8.832) </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n*Note. The grade coefficients are increasingly negative because they are positively correlated with pre-test scores. Remember, **we cannot interpret confounders causally**[see @westreich2013].*\n\nAnd here's a separate model for each grade:\n\n\n::: {#fig-electric .cell layout-ncol=\"2\"}\n\n```{.r .cell-code  code-fold=\"true\"}\nfit1 <- map_df(1:4, function(i) {\n  lm(formula = post_test ~ supp, \n     data = d, \n     subset = grade == i) |> \n    broom::tidy() |> \n    filter(term == \"supp\") |> \n    mutate(grade = paste(\"Grade\", i))\n})\n\nfit2 <- map_df(1:4, function(i) {\n  lm(formula = post_test ~ supp + pre_test, \n     data = d, \n     subset = grade == i) |> \n    broom::tidy() |> \n    filter(term == \"supp\") |> \n    mutate(grade = paste(\"Grade\", i))\n})\n\nfit1 |> \n  ggplot(aes(estimate, grade)) + \n  geom_vline(xintercept = 0, linetype = \"dashed\") +\n  geom_linerange(aes(\n    xmin = estimate + std.error*qnorm(0.05),\n    xmax = estimate + std.error*qnorm(0.95)), \n  ) +\n  geom_linerange(aes(\n    xmin = estimate + std.error*qnorm(0.25),\n    xmax = estimate + std.error*qnorm(0.75)\n    ), linewidth = 1.5\n  ) +\n  geom_point(shape = 21, fill = \"white\") + \n  labs(y = NULL, x = \"treatment\",\n       title = \"lm(post_treat ~ supp)\")\n\nfit2 |> \n  ggplot(aes(estimate, grade)) + \n  geom_vline(xintercept = 0, linetype = \"dashed\") +\n  geom_linerange(aes(\n    xmin = estimate + std.error*qnorm(0.05),\n    xmax = estimate + std.error*qnorm(0.95)), \n  ) +\n  geom_linerange(aes(\n    xmin = estimate + std.error*qnorm(0.25),\n    xmax = estimate + std.error*qnorm(0.75)\n    ), linewidth = 1.5\n  ) +\n  geom_point(shape = 21, fill = \"white\") + \n  labs(y = NULL, x = \"treatment\",\n       title = \"lm(post_treat ~ supp + pre_test)\")\n```\n\n::: {.cell-output-display}\n![Regression on non-random treatment indicator](causality-02-regression_files/figure-html/fig-electric-1.png){#fig-electric-1 width=384}\n:::\n\n::: {.cell-output-display}\n![Regression on non-random treatment indicator and pre-test](causality-02-regression_files/figure-html/fig-electric-2.png){#fig-electric-2 width=384}\n:::\n\nEstimates, 50%, and 95% intervals for the effect of watching The Electric Company _as a supplement rather than a replacement_. The same model has been fitted separately for each grade.\n:::\n\n\n## Notation\n\nThe logic of regression adjustments is relatively straightforward, we want *apples to apples* comparisons. This is the same logic behind matching and weighting.\n\nInstead of a simple independence assumption that we have for randomized experiments, we now have to rely on a **conditional** ignorability. Just like in the case of experiments, we want distribution of potential outcomes the same across levels of the treatment variable. In other words, the potential outcomes and the treatment indicator *should* be independent, conditional on the covariates $\\boldsymbol{X}$ used in the analysis.\n\n<aside>*Ignorability, Conditional Independence Assumption (CIA), or Selection on Observables*</aside>\n\n$$\nY^0, Y^1 \\perp T \\mid \\boldsymbol X\n$$ {#eq-cond-ind}\n\nThus, in expectation:\n\n$$\n\\begin{align}\nE\\big[Y^1 \\mid T=1, \\boldsymbol{X} \\big] &= E\\big[Y^1 \\mid T=0, \\boldsymbol{X} \\big] \\\\\nE\\big[Y^0 \\mid T=1, \\boldsymbol{X} \\big] &= E\\big[Y^0 \\mid T=0, \\boldsymbol{X} \\big]\n\\end{align}\n$$ {#eq-cond-ind-2}\n\nThese conditional quantities can be used to construct the marginal effects needed to construct the *average treatment effect.*\n\n$$\n\\text{ATE} = E[Y^1 - Y^0] = \\underbrace{E\\Big[E[Y^1 \\mid \\boldsymbol{X}] \\Big] - E \\Big[E[Y^0 \\mid \\boldsymbol{X}] \\Big] = E[Y^1] - E[Y^0]}_\\text{Law of Iterated Expectations}\n$$ {#eq-iterated-ate}\n\nThis strategy will get more complicated as the vector $\\boldsymbol X$ grows in size.\n\n> Once the number and type of confounders gets more complicated, perhaps the simplest parametric model that we can fit to estimate these expectations is linear regression. For instance, if we assume that the treatment effect, $\\tau$, is constant (or at least additive) we might posit that $E( Y^Z \\mid \\boldsymbol X) = \\beta_0+ \\boldsymbol{X \\beta}+ \\tau Z$ . If ignorability is satisfied and this model holds, we simply need to regress the outcome on the treatment indicator and confounders. The estimated coefficient on $Z$ from this fit, $\\hat \\tau$, can be conceptualized as a weighted version of all of the conditional effect estimates. However, fitting a model to estimate these quantities is not without potential weaknesses. The two most obvious concerns are imbalance and lack of complete overlap...\n>\n> @gelman2020 [pp. 390]\n\n*Note. This sometimes shows up in econometrics as the **exogeneity assumption***.\n\n## Balance and Overlap\n\nThe sort of bias that we get from confounding can be interpreted more precisely as **imbalance** in the potential outcomes across treatment groups. This is the sort of imbalance is unlikely with *randomization*, but it's almost guaranteed in observational studies.\n\nThere are different methods that attempt to address imbalance and lack of overlap: stratification, regression adjustments, matching, weighting, or a combination of these.\n\n> Imbalance and lack of complete overlap are issues for causal inference even if ignorability holds because they force us to rely more heavily on model specification and less on direct support from the data.\n>\n> @gelman2020 [pp. 391]\n\n### Imbalance\n\nImbalance occurs if the distributions of confounders differ for the treatment and control groups. @fig-imbalance shows two examples of imbalance with respect to a single covariate $x$. The problem with imbalance is that it forces us to rely more heavily on model specification and less on direct support from the data. This is true even if ignorability holds.\n\n\n::: {#fig-imbalance .cell layout-ncol=\"2\"}\n\n```{.r .cell-code  code-fold=\"true\"}\nggplot() + \n  xlim(0, 1) +\n  geom_function(fun = \\(x) dbeta(x, 5, 2)) +\n  geom_function(fun = \\(x) dbeta(x, 2, 5), linetype = \"dashed\") +\n  geom_vline(xintercept = c(0.4, 0.6), linetype = \"dotted\") +\n  labs(x = \"X\", y = NULL) +\n  theme_bw(base_family = \"Avenir Next Condensed\", base_line_size = 0) + \n  theme(axis.text = element_blank()) \n\nggplot() + \n  xlim(0, 1) +\n  geom_function(fun = \\(x) dbeta(x, 3, 2.2), linetype = \"dashed\") +\n  geom_function(fun = \\(x) dbeta(x, 2.2, 3)) +\n  geom_vline(xintercept = 0.5, linetype = \"dotted\") +\n  labs(x = \"X\", y = NULL) +\n  theme_bw(base_family = \"Avenir Next Condensed\", base_line_size = 0) + \n  theme(axis.text = element_blank()) \n```\n\n::: {.cell-output-display}\n![The groups differ in their averages but cover the same range of $x$](causality-02-regression_files/figure-html/fig-imbalance-1.png){#fig-imbalance-1 width=384}\n:::\n\n::: {.cell-output-display}\n![A more subtle form of imbalance, the groups have the same average but different distributions](causality-02-regression_files/figure-html/fig-imbalance-2.png){#fig-imbalance-2 width=384}\n:::\n\nImbalance in distributions across treatment and control groups\n:::\n\n\nConsider what happens if we try to make inferences about the effect of a treatment $\\theta$ on $y$, while adjusting for $x$.\n\n$$\n\\begin{align}\n\\text{treated:}  &&y_i &= \\beta_0 + \\theta + \\beta_1 x_i + \\beta_2 x_i^2 + \\varepsilon_i \\\\ \\\\\n\\text{control:} &&y_i &= \\beta_0 + \\beta_1 x_i + \\beta_2 x_i^2 + \\varepsilon_i\n\\end{align}\n$$\n\nAveraging over each group separately, solving the second equation for $\\beta_0$, and then plugging that into the first equation to solve for $\\theta$ yields the following equation:\n\n$$\n\\theta = (\\overline y_t - \\overline y_c) - \\underbrace{\\beta_1 (\\overline x_t - \\overline x_c) - \\beta_2 (\\overline {x^2_t} - \\overline {x^2_c})}_\\text{adjustment}\n$$ {#eq-reg-adjust}\n\nThis is why it's so important to get the model specification right. For example, notice that if we don't include the quadratic term in the linear model, the estimate of $\\theta$ will be off by $\\beta_2 (\\overline {x^2_t} - \\overline {x^2_c})$.\n\nMore importantly, if the distribution of covariates is similar across treatment groups, then the model specification matters less---i.e., if there is balance, then $\\overline x_t - \\overline x_c$ is closer to zero. This is why methods that match or weight to create balance may help to create some immunity from failure to correctly specify the model.\n\n### Lack of Complete Overlap\n\n@fig-overlap shows what lack of complete overlap (with respect to $x$) might look like:\n\n\n::: {#fig-overlap .cell layout-ncol=\"3\"}\n\n```{.r .cell-code  code-fold=\"true\"}\nggplot() + \n  xlim(-4, 10) + \n  geom_function(fun = \\(x) dnorm(x, -1, 1), linetype = \"dashed\") +\n  geom_function(fun = \\(x) dnorm(x, 7, 1)) + \n  theme_bw(base_family = \"Avenir Next Condensed\", base_line_size = 0) + \n  theme(axis.text = element_blank()) + \n  labs(x = \"X\", y = NULL, title = \"No overlap\")\n\nggplot() + \n  xlim(-4, 10) + \n  geom_function(fun = \\(x) dnorm(x, 1, 1), linetype = \"dashed\") +\n  geom_function(fun = \\(x) dnorm(x, 4, 1)) + \n  theme_bw(base_family = \"Avenir Next Condensed\", base_line_size = 0) + \n  theme(axis.text = element_blank()) + \n  labs(x = \"X\", y = NULL, title = \"Partial overlap\")\n\nggplot() + \n  xlim(-4, 10) + \n  geom_function(fun = \\(x) dnorm(x, 2, 3), linetype = \"dashed\") +\n  geom_function(fun = \\(x) dnorm(x, 7, 1)) + \n  theme_bw(base_family = \"Avenir Next Condensed\", base_line_size = 0) + \n  theme(axis.text = element_blank()) + \n  labs(x = \"X\", y = NULL, title = \"Partial overlap\")\n```\n\n::: {.cell-output-display}\n![Two distributions with no overlap](causality-02-regression_files/figure-html/fig-overlap-1.png){#fig-overlap-1 width=240}\n:::\n\n::: {.cell-output-display}\n![Two distributions with partial overlap](causality-02-regression_files/figure-html/fig-overlap-2.png){#fig-overlap-2 width=240}\n:::\n\n::: {.cell-output-display}\n![The _range_ of one distribution is a subset of the range of the other.](causality-02-regression_files/figure-html/fig-overlap-3.png){#fig-overlap-3 width=240}\n:::\n\nLack of complete overlap in distributions across treatment and control groups.\n:::\n\n\nLack of complete overlap or \"common support\" creates problems because in this setting we have treatment or control observations for which we have *no empirical counterfactuals*. Thus, knowledge about treatment effects is inherently limited in regions of non-overlap. Any causal inference in @fig-overlap-1 would rely on modeling assumptions instead of having direct support from the data. In @fig-overlap-3 causal inference is possible for the full treatment group but only for a subset of the control group.\n\n> There is an important correspondence between areas of overlap and the estimand of interest, and it can make sense to choose your inferential goal based on the support in the data.\n>\n> @gelman2020 [pp. 392]\n\n<aside>ATE, ATT, or ATU?</aside>\n\n@fig-extrapolation shows how inferences regarding areas with no overlap inevitably rely on modeling assumptions. A traditional regression model fitted to data without complete overlap is *forced to extrapolate* beyond the support of the data.\n\nNote, however, that even the incorrectly specified linear regression lines provide a decent fit *in the overlapping region*, as shown in @fig-extrapolation-3 and @fig-extrapolation-4.\n\n\n::: {#fig-extrapolation .cell layout-ncol=\"2\"}\n\n```{.r .cell-code  code-fold=\"true\"}\nfY1 <- function(x) exp(x/5) + 2*cos(x + 1) + 15\nfY0 <- function(x) 6*log(x + 1) - 0.08*x^2 + 5\n\nd_sim <- tibble(\n  x = runif(100, 0, 10),\n  control = rnorm(length(x), mean = fY0(x), sd = 1),\n  treatment = rnorm(length(x), mean = fY1(x), sd = 1),\n) |> \n  tidyr::pivot_longer(\n    cols = control:treatment, \n    names_to = \"z\", \n    values_to = \"y\", \n    names_transform = factor\n  ) |> \n  filter(z == \"control\" & x <= 7 | z == \"treatment\" & x >= 3)\n\npar_s <- lm(y ~ x + z, data = d_sim)\nvar_s <- lm(y ~ x*z, data = d_sim)\nsub_par_s <- lm(y ~ x + z, data = d_sim, subset = x >= 3 & x <= 7)\n\ng <- d_sim |> \n  ggplot(aes(x, y)) + \n  geom_function(fun = fY0) + \n  geom_function(fun = fY1) + \n  geom_point(aes(shape = z), show.legend = FALSE, \n             fill = \"skyblue\", color = \"#4C4C4C\", size = 1) + \n  scale_shape_manual(values = c(19, 21)) +\n  labs(x = \"X\", y = \"Y\") +\n  theme_bw(base_family = \"Avenir Next Condensed\", base_line_size = 0) +\n  theme(\n    axis.title.y = element_text(angle = 0, vjust = 1/2),\n    axis.text = element_blank(),\n    axis.ticks = element_blank(),\n    panel.grid = element_blank()\n  ) \n\nd_grid <- tidyr::crossing(\n  x = seq(0, 10, length.out = 100),\n  z = factor(c(\"control\", \"treatment\"))\n)\n\ng +\n  geom_line(\n    data = broom::augment(par_s, newdata = d_grid),\n    mapping = aes(x, .fitted, group = z),\n    linetype = \"dashed\"\n  )\n\ng +\n  geom_line(\n    data = broom::augment(var_s, newdata = d_grid),\n    mapping = aes(x, .fitted, group = z),\n    linetype = \"dashed\"\n  )\n\ng +\n  coord_cartesian(xlim = c(3, 7)) +\n    geom_line(\n    data = broom::augment(par_s, newdata = d_grid),\n    mapping = aes(x, .fitted, group = z),\n    linetype = \"dashed\"\n  )\n\ng +\n  coord_cartesian(xlim = c(3, 7)) +\n  geom_line(\n    data = broom::augment(sub_par_s, newdata = d_grid),\n    mapping = aes(x, .fitted, group = z),\n    linetype = \"dashed\"\n  )\n```\n\n::: {.cell-output-display}\n![A regression estimating the effect of treatment $T$ on $Y$, adjusting for $X$.](causality-02-regression_files/figure-html/fig-extrapolation-1.png){#fig-extrapolation-1 width=240}\n:::\n\n::: {.cell-output-display}\n![Allowing for an interaction sometimes makes extrapolation worse.](causality-02-regression_files/figure-html/fig-extrapolation-2.png){#fig-extrapolation-2 width=240}\n:::\n\n::: {.cell-output-display}\n![The view is restricted to the area of overlap.](causality-02-regression_files/figure-html/fig-extrapolation-3.png){#fig-extrapolation-3 width=240}\n:::\n\n::: {.cell-output-display}\n![New regression lines fitted using only observations in this overlapping region.](causality-02-regression_files/figure-html/fig-extrapolation-4.png){#fig-extrapolation-4 width=240}\n:::\n\nHypothetical data demonstrating the problems with extrapolation when there is lack of overlap between covariates. The \"true\" causal effect is the vertical distance between the two solid lines. The estimated causal effect is the vertical distance between the two dashed lines.\n:::\n\n\nThe dataset from the example in @fig-balance-childcare comes from a sample of nearly 4500 children born in the 1980s. A subset of 290 received several healthcare interventions; these children were targeted because they were born prematurely, had low birth weight, and lived in the eight cities were the intervention took place. We can start checking for imbalance for several covariates by examining their absolute standardized difference in means---i.e., a **balance plot**. @fig-balance-childcare-2 displays the *absolute standardized difference in means values* for a set of confounding covariates that might predict both program participation and subsequent test scores.\n\n\n::: {#fig-balance-childcare .cell layout-ncol=\"2\"}\n\n```{.r .cell-code  code-fold=\"true\"}\nurl <- \"https://raw.githubusercontent.com/avehtari/ROS-Examples/master/Childcare/data/cc2.csv\"\nd <- read_csv(url)[-1]\nd$momage <- sqrt(d$momageT)\n\ncovs <- c(\n  'birth weight' = 'bw',\n  'weeks preterm' = 'preterm', \n  'days in hospital' = 'dayskidh', \n  'male' = 'sex', \n  'first born' = 'first', \n  'age' = 'age', \n  'black' = 'black', \n  'hispanic' = 'hispanic', \n  'white' = 'white', \n  'unmarried at birth' = 'b.marr', \n  'less than high school' = 'lths', \n  'high school graduate' = 'hs', \n  'some college' = 'ltcoll', \n  'college graduate' = 'college', \n  'worked during pregnancy' = 'work.dur', \n  'had no prenatal care' = 'prenatal', \n  'age at birth' = 'momage'\n)\n\nd |> \n  mutate(treat = fct_rev(factor(treat))) |> \n  filter(between(bw, 1500, 5000)) |> \n  ggplot(aes(bw, ppvtr.36)) +\n  geom_point(aes(color = treat), size = 2/3) + \n  geom_smooth(aes(linetype = treat), method = \"lm\", linewidth = 1/2,\n              fullrange = TRUE, se = FALSE, color = \"#323232\") + \n  scale_color_grey() + \n  labs(x = \"birth weight\", y = \"test score at age 3\", \n       color = \"treatment\", linetype = \"treatment\") +\n  theme(legend.position = \"bottom\")\n\n## treatment indicator\nt <- which(as.logical(d$treat))\n\navg1 <- apply(d[t, covs], 2, mean)\navg0 <- apply(d[-t, covs], 2, mean)\nsd1 <- apply(d[t, covs], 2, sd) ## only uses sd of treated\nz <- (avg1 - avg0) / sd1\n\ntibble(var = covs, diff = z, label = names(covs)) |> \n  mutate(label = reorder(label, abs(diff))) |> \n  ggplot(aes(abs(diff), label)) + \n  geom_segment(aes(xend = abs(diff), yend = label), x = 0) + \n  geom_point(shape = 21, fill = \"white\") + \n  labs(y = NULL, x = \"Absolute Standardized Differences in Means\")\n```\n\n::: {.cell-output-display}\n![Regression lines of test scores on birth weight (separately by treatment groups)](causality-02-regression_files/figure-html/fig-balance-childcare-1.png){#fig-balance-childcare-1 width=384}\n:::\n\n::: {.cell-output-display}\n![Imbalance in averages of confounding covariates across treatment groups.](causality-02-regression_files/figure-html/fig-balance-childcare-2.png){#fig-balance-childcare-2 width=384}\n:::\n\nLack of complete overlap. If birth weight is a confounding covariate, then we will have to rely on model extrapolations to make inferences about the effect of the program on children with birth weights over 2500 grams.\n:::\n\n\n*Note. Lack of overlap is not the same as imbalance.*\n\nThe next notebook discusses **matching/weighting** as strategies that help us deal with imbalance and rely less on modeling assumptions to deal with data outside the area of common support.\n\n## Exercises\n",
    "supporting": [
      "causality-02-regression_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}